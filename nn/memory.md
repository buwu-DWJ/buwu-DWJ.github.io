# 循环神经网络
**循环神经网络**（Recurrent Neural Network，RNN）是一类具有短期记忆能力的神经网络．在循环神经网络中，神经元不但可以接受其他神经元的信息，也可以接受自身的信息，形成具有环路的网络结构．和前馈神经网络相比，循环神经网络更加符合生物神经网络的结构．循环神经网络已经被广泛应用在语音识别、语言模型以及自然语言生成等任务上．循环神经网络的参数学习可以通过**随时间反向传播算法**来学习．随时间反向传播算法即按照时间的逆序将错误信息一步步地往前传递．当输入序列比较长时，会存在梯度爆炸和消失问题，也称为长程依赖问题．为了解决这个问题，人们对循环神经网络进行了很多的改进，其中最有效的改进方式引入**门控机制**（Gating Mechanism）．  
此外，循环神经网络可以很容易地扩展到两种更广义的记忆网络模型：递归神经网络和图网络．
# 1. 循环神经网络  
给定一个输入序列 $x_{1:T} = (x_1,x_2,...,x_t,...,x_T)$ ，循环神经网络通过下面公式更新带反馈边的隐藏层的活性值 $h_t$：
$$
h_t = f(h_{t-1},x_t),
$$
其中 $h_0 = 0$ ，$f(\cdot)$ 为一个非线性函数，可以是一个前馈网络．  
给出了循环神经网络的示例，其中“延时器”为一个虚拟单元，记录神经元的最近一次（或几次）活性值．
![](images/5.JPG)  
从数学上讲，上式可以看成一个动力系统．因此，隐藏层的活性值 $h_t$ 在很多文献上也称为状态（State）或隐状态（Hidden State）．由于循环神经网络具有短期记忆能力，相当于存储装置，因此其计算能力十分强大．理论上，循环神经网络可以近似任意的非线性动力系统．前馈神经网络可以模拟任何连续函数，而循环神经网络可以模拟任何程序．
# 2. 简单循环网络  
简单循环网络（Simple Recurrent Network，SRN）只有一个隐藏层．在一个两层的前馈神经网络中，连接存在于相邻的层与层之间，隐藏层的节点之间是无连接的．而简单循环网络增加了从隐藏层到隐藏层的反馈连接．  
令向量 $x_t\in \mathbb{R}^M$ 表示在时刻 $t$ 时网络的输入， $h_t\in \mathbb{R}^D$ 表示隐藏层状态（即隐藏层神经元活性值），则 $h_t$ 不仅和当前时刻的输入 $x_t$ 相关，也和上一个时刻的隐藏层状态 $h_{t-1}$ 相关．简单循环网络在时刻 $t$ 的更新公式为
$$
z_{t}=\boldsymbol{U} \boldsymbol{h}_{t-1}+\boldsymbol{W} \boldsymbol{x}_{t}+\boldsymbol{b}
$$
其中 $z_t$ 为隐藏层的净输入， $U\in \mathbb{R}^{D\times D}$ 为状态-状态权重矩阵， $W\in \mathbb{R}^{D\timesM$ 为状态-输入权重矩阵，$b\in \mathbb{R}^D$ 为偏置向量，$f(\cdot)$ 是非线性激活函数，通常为Logistic函数或Tanh函数．也经常直接写为
$$
\boldsymbol{h}_{t}=f\left(\boldsymbol{U} \boldsymbol{h}_{t-1}+\boldsymbol{W} \boldsymbol{x}_{t}+\boldsymbol{b}\right)
$$
下图给出了按时间展开的循环神经网络：
![](img/2.PNG)  
#### 循环神经网络的通用近似定理
一个完全连接的循环网络是任何非线性动力系统的近似器．
**定理：循环神经网络的通用近似定理[Haykin,2009]**：如果一个完全连接的循环神经网络有足够数量的sigmoid型隐藏神经元，那么它可以以任意的准确率去近似任何一个非线性动力系统
$$
\begin{array}{l}
\boldsymbol{s}_{t}=g\left(\boldsymbol{s}_{t-1}, \boldsymbol{x}_{t}\right), \\
\boldsymbol{y}_{t}=o\left(\boldsymbol{s}_{t}\right),
\end{array}
$$
其中 $s_t$ 为每个时刻的隐状态， $x_t$ 是外部输入， $g(\cdot)$ 是可测的状态转换函数， $o(\cdot)$ 是连续输出函数，并且对状态空间的紧致性没有限制．  
# 3. 应用于机器学习
# 4. 参数学习
#### 随时间反向传播
#### 实时循环学习
TODO:RNN反向传播  
